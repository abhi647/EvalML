{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n","metadata":{}},{"cell_type":"markdown","source":"# Why EvalML is one of the best AutoML library you can get your hands on","metadata":{}},{"cell_type":"markdown","source":"## What is AutoML?\n\n**According to wikipedia** -\n\nAutomated machine learning (*AutoML*) is the process of automating the tasks of applying machine learning to real-world problems. AutoML covers the complete pipeline from the raw dataset to the deployable machine learning model. AutoML was proposed as an artificial intelligence-based solution to the ever-growing challenge of applying machine learning.The high degree of automation in AutoML allows non-experts to make use of machine learning models and techniques without requiring them to become experts in machine learning. Automating the process of applying machine learning end-to-end additionally offers the advantages of producing simpler solutions, faster creation of those solutions, and models that often outperform hand-designed models. AutoML has been used to compare the relative importance of each factor in a prediction model.","metadata":{}},{"cell_type":"markdown","source":"# What is EvalML?\nEvalML is an open source automated machine learning library created by Altryx's Innovation team EvalML is an AutoML library that builds, optimizes, and evaluates machine learning pipelines using domain-specific objective functions.\n\nBasically EvalML provides a simple low code interface to create machine learning model and use those models to generate insights and to make accurate predictions.    \n\n## What I liked the most about EvalML\n\n- EvalML cuts downs the process of model training and tuning by hand, this includes data quality checks and cross-validation.\n\n- Data Checks and warnings: EvalML helps you in identifying the probelm in the data before using or setting it up for modelling\n\n- Pipeline building: EvalML helps you in consructing a highly optimised pipeline including a state-of-the-art data preprocessing, feature engineering, feature selection and a lot pf modelling techniques \n\n- Model Understanding: Just like Shap, Eli5, Lime and other model explanibility libraries EvalML also provides a broad level of understanding about the model you are building, for the purpose of presentation\n\n- Domain-specific: This is the missing link in most of the AutoML libraries where you can define the objective if the problem. Once you have determined the objective for your business, you can provide that to EvalML to optimize by defining a custom objective function. ","metadata":{}},{"cell_type":"markdown","source":"# Let's get started with EvalML","metadata":{}},{"cell_type":"markdown","source":"## How to install ","metadata":{}},{"cell_type":"markdown","source":"> **Note:** EvalML includes several optional dependencies. The xgboost and catboost packages support pipelines built around those modeling libraries. The plotly and ipywidgets packages support plotting functionality in automl searches. These dependencies are recommended, and are included with EvalML by default but are not required in order to install and use EvalML","metadata":{}},{"cell_type":"code","source":"!pip install evalml","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"scrolled":true,"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Requirement already satisfied: evalml in /opt/conda/lib/python3.7/site-packages (0.24.0)\nRequirement already satisfied: pyzmq<22.0.0 in /opt/conda/lib/python3.7/site-packages (from evalml) (21.0.2)\nRequirement already satisfied: click>=7.0.0 in /opt/conda/lib/python3.7/site-packages (from evalml) (7.1.2)\nRequirement already satisfied: plotly>=4.14.0 in /opt/conda/lib/python3.7/site-packages (from evalml) (4.14.3)\nRequirement already satisfied: scikit-optimize>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from evalml) (0.8.1)\nRequirement already satisfied: psutil>=5.6.3 in /opt/conda/lib/python3.7/site-packages (from evalml) (5.8.0)\nRequirement already satisfied: seaborn>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from evalml) (0.11.1)\nRequirement already satisfied: numpy>=1.19.1 in /opt/conda/lib/python3.7/site-packages (from evalml) (1.19.5)\nRequirement already satisfied: statsmodels>=0.12.2 in /opt/conda/lib/python3.7/site-packages (from evalml) (0.12.2)\nRequirement already satisfied: scipy>=1.2.1 in /opt/conda/lib/python3.7/site-packages (from evalml) (1.5.4)\nRequirement already satisfied: featuretools>=0.20.0 in /opt/conda/lib/python3.7/site-packages (from evalml) (0.23.3)\nRequirement already satisfied: cloudpickle>=0.2.2 in /opt/conda/lib/python3.7/site-packages (from evalml) (1.6.0)\nRequirement already satisfied: category-encoders>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from evalml) (2.2.2)\nRequirement already satisfied: imbalanced-learn>=0.8.0 in /opt/conda/lib/python3.7/site-packages (from evalml) (0.8.0)\nRequirement already satisfied: texttable>=1.6.2 in /opt/conda/lib/python3.7/site-packages (from evalml) (1.6.3)\nRequirement already satisfied: ipywidgets>=7.5 in /opt/conda/lib/python3.7/site-packages (from evalml) (7.6.3)\nRequirement already satisfied: xgboost<1.3.0,>=0.82 in /opt/conda/lib/python3.7/site-packages (from evalml) (1.2.1)\nRequirement already satisfied: dask>=2.12.0 in /opt/conda/lib/python3.7/site-packages (from evalml) (2021.4.0)\nRequirement already satisfied: pandas>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from evalml) (1.2.3)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.7/site-packages (from evalml) (0.4.4)\nRequirement already satisfied: kaleido>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from evalml) (0.2.1)\nRequirement already satisfied: woodwork==0.0.11 in /opt/conda/lib/python3.7/site-packages (from evalml) (0.0.11)\nRequirement already satisfied: networkx>=2.5 in /opt/conda/lib/python3.7/site-packages (from evalml) (2.5)\nRequirement already satisfied: graphviz>=0.13 in /opt/conda/lib/python3.7/site-packages (from evalml) (0.16)\nRequirement already satisfied: requirements-parser>=0.2.0 in /opt/conda/lib/python3.7/site-packages (from evalml) (0.2.0)\nRequirement already satisfied: shap>=0.36.0 in /opt/conda/lib/python3.7/site-packages (from evalml) (0.39.0)\nRequirement already satisfied: catboost>=0.20 in /opt/conda/lib/python3.7/site-packages (from evalml) (0.25.1)\nRequirement already satisfied: lightgbm<3.1.0,>=2.3.1 in /opt/conda/lib/python3.7/site-packages (from evalml) (3.0.0)\nRequirement already satisfied: scikit-learn>=0.23.1 in /opt/conda/lib/python3.7/site-packages (from evalml) (0.24.1)\nRequirement already satisfied: matplotlib>=3.3.3 in /opt/conda/lib/python3.7/site-packages (from evalml) (3.4.1)\nRequirement already satisfied: sktime>=0.5.3 in /opt/conda/lib/python3.7/site-packages (from evalml) (0.6.1)\nRequirement already satisfied: nlp-primitives>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from evalml) (1.1.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from catboost>=0.20->evalml) (1.15.0)\nRequirement already satisfied: patsy>=0.5.1 in /opt/conda/lib/python3.7/site-packages (from category-encoders>=2.0.0->evalml) (0.5.1)\nRequirement already satisfied: fsspec>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from dask>=2.12.0->evalml) (0.8.7)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from dask>=2.12.0->evalml) (5.3.1)\nRequirement already satisfied: partd>=0.3.10 in /opt/conda/lib/python3.7/site-packages (from dask>=2.12.0->evalml) (1.2.0)\nRequirement already satisfied: toolz>=0.8.2 in /opt/conda/lib/python3.7/site-packages (from dask>=2.12.0->evalml) (0.11.1)\nRequirement already satisfied: tqdm>=4.32.0 in /opt/conda/lib/python3.7/site-packages (from featuretools>=0.20.0->evalml) (4.59.0)\nRequirement already satisfied: distributed>=2.12.0 in /opt/conda/lib/python3.7/site-packages (from featuretools>=0.20.0->evalml) (2021.4.0)\nRequirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /opt/conda/lib/python3.7/site-packages (from distributed>=2.12.0->featuretools>=0.20.0->evalml) (2.3.0)\nRequirement already satisfied: msgpack>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from distributed>=2.12.0->featuretools>=0.20.0->evalml) (1.0.2)\nRequirement already satisfied: tornado>=5 in /opt/conda/lib/python3.7/site-packages (from distributed>=2.12.0->featuretools>=0.20.0->evalml) (6.1)\nRequirement already satisfied: tblib>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from distributed>=2.12.0->featuretools>=0.20.0->evalml) (1.7.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from distributed>=2.12.0->featuretools>=0.20.0->evalml) (49.6.0.post20210108)\nRequirement already satisfied: zict>=0.1.3 in /opt/conda/lib/python3.7/site-packages (from distributed>=2.12.0->featuretools>=0.20.0->evalml) (2.0.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from fsspec>=0.6.0->dask>=2.12.0->evalml) (3.4.0)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn>=0.8.0->evalml) (1.0.1)\nRequirement already satisfied: widgetsnbextension~=3.5.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets>=7.5->evalml) (3.5.1)\nRequirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.7/site-packages (from ipywidgets>=7.5->evalml) (5.0.5)\nRequirement already satisfied: nbformat>=4.2.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets>=7.5->evalml) (5.1.2)\nRequirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.7/site-packages (from ipywidgets>=7.5->evalml) (5.5.0)\nRequirement already satisfied: ipython>=4.0.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets>=7.5->evalml) (7.22.0)\nRequirement already satisfied: jupyterlab-widgets>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets>=7.5->evalml) (1.0.0)\nRequirement already satisfied: jupyter-client in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.5->evalml) (6.1.12)\nRequirement already satisfied: backcall in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets>=7.5->evalml) (0.2.0)\nRequirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets>=7.5->evalml) (0.18.0)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets>=7.5->evalml) (3.0.18)\nRequirement already satisfied: pygments in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets>=7.5->evalml) (2.8.1)\nRequirement already satisfied: pickleshare in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets>=7.5->evalml) (0.7.5)\nRequirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets>=7.5->evalml) (4.4.2)\nRequirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets>=7.5->evalml) (4.8.0)\nRequirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.7/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets>=7.5->evalml) (0.8.1)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.3.3->evalml) (1.3.1)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.3.3->evalml) (7.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.3.3->evalml) (0.10.0)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.3.3->evalml) (2.4.7)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.3.3->evalml) (2.8.1)\nRequirement already satisfied: jupyter-core in /opt/conda/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets>=7.5->evalml) (4.7.1)\nRequirement already satisfied: ipython-genutils in /opt/conda/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets>=7.5->evalml) (0.2.0)\nRequirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets>=7.5->evalml) (3.2.0)\nRequirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.5->evalml) (0.17.3)\nRequirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.5->evalml) (20.3.0)\nRequirement already satisfied: nltk>=3.4.5 in /opt/conda/lib/python3.7/site-packages (from nlp-primitives>=1.1.0->evalml) (3.6.2)\nRequirement already satisfied: regex in /opt/conda/lib/python3.7/site-packages (from nltk>=3.4.5->nlp-primitives>=1.1.0->evalml) (2021.3.17)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=1.1.0->evalml) (2021.1)\nRequirement already satisfied: locket in /opt/conda/lib/python3.7/site-packages (from partd>=0.3.10->dask>=2.12.0->evalml) (0.2.1)\nRequirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.7/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets>=7.5->evalml) (0.7.0)\nRequirement already satisfied: retrying>=1.3.3 in /opt/conda/lib/python3.7/site-packages (from plotly>=4.14.0->evalml) (1.3.3)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets>=7.5->evalml) (0.2.5)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.23.1->evalml) (2.1.0)\nRequirement already satisfied: pyaml>=16.9 in /opt/conda/lib/python3.7/site-packages (from scikit-optimize>=0.8.1->evalml) (20.4.0)\nRequirement already satisfied: numba in /opt/conda/lib/python3.7/site-packages (from shap>=0.36.0->evalml) (0.53.1)\nRequirement already satisfied: slicer==0.0.7 in /opt/conda/lib/python3.7/site-packages (from shap>=0.36.0->evalml) (0.0.7)\nRequirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from sktime>=0.5.3->evalml) (0.36.2)\nRequirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in /opt/conda/lib/python3.7/site-packages (from numba->shap>=0.36.0->evalml) (0.36.0)\nRequirement already satisfied: notebook>=4.4.1 in /opt/conda/lib/python3.7/site-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.5->evalml) (6.3.0)\nRequirement already satisfied: nbconvert in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5->evalml) (6.0.7)\nRequirement already satisfied: Send2Trash>=1.5.0 in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5->evalml) (1.5.0)\nRequirement already satisfied: argon2-cffi in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5->evalml) (20.1.0)\nRequirement already satisfied: prometheus-client in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5->evalml) (0.9.0)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5->evalml) (2.11.3)\nRequirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5->evalml) (0.9.3)\nRequirement already satisfied: heapdict in /opt/conda/lib/python3.7/site-packages (from zict>=0.1.3->distributed>=2.12.0->featuretools>=0.20.0->evalml) (1.0.1)\nRequirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5->evalml) (1.14.5)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5->evalml) (2.20)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->fsspec>=0.6.0->dask>=2.12.0->evalml) (3.7.4.3)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->fsspec>=0.6.0->dask>=2.12.0->evalml) (3.4.1)\nRequirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.7/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5->evalml) (1.1.1)\nRequirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5->evalml) (0.8.4)\nRequirement already satisfied: defusedxml in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5->evalml) (0.7.1)\nRequirement already satisfied: entrypoints>=0.2.2 in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5->evalml) (0.3)\nRequirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5->evalml) (0.5.3)\nRequirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5->evalml) (0.1.2)\nRequirement already satisfied: testpath in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5->evalml) (0.4.4)\nRequirement already satisfied: bleach in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5->evalml) (3.3.0)\nRequirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5->evalml) (1.4.2)\nRequirement already satisfied: nest-asyncio in /opt/conda/lib/python3.7/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5->evalml) (1.4.3)\nRequirement already satisfied: async-generator in /opt/conda/lib/python3.7/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5->evalml) (1.10)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5->evalml) (20.9)\nRequirement already satisfied: webencodings in /opt/conda/lib/python3.7/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5->evalml) (0.5.1)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Loading a dataset","metadata":{}},{"cell_type":"markdown","source":"Loading a dataset in EvalMl is just the usual process we can use any library for this, I am using pandas for this and I am using breast cancer dataset for this\nDataset Link: [Breast Cancer Dataset](https://www.kaggle.com/uciml/breast-cancer-wisconsin-data)","metadata":{}},{"cell_type":"code","source":"import evalml\nX, y = evalml.demos.load_breast_cancer()\nX_train, X_test, y_train, y_test = evalml.preprocessing.split_data(X, y, problem_type='binary')\n# Here we'll split the data table using evalml's preprocessing \"split_data\" library","metadata":{"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"Note: EvalML uses data tables as a standard data format but you can read the regular .csv dataset and it gets converted using Woorworks (another altryx project). \nEvalML also accepts and works well with pandas DataFrames. But using the DataTable makes it easy to control how EvalML will treat each feature, as a numeric feature, a categorical feature, a text feature or other type of feature. Woodwork’s DataTable includes features like inferring when a categorical feature should be treated as a text feature.","metadata":{}},{"cell_type":"code","source":"X_train.head()","metadata":{"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"Data Column     mean radius mean texture mean perimeter   mean area  \\\nPhysical Type       float64      float64        float64     float64   \nLogical Type         Double       Double         Double      Double   \nSemantic Tag(s) ['numeric']  ['numeric']    ['numeric'] ['numeric']   \n381                   11.04        14.93          70.67       372.7   \n144                   10.75        14.97          68.26       355.3   \n136                   11.71        16.67          74.72       423.6   \n116                    8.95        15.76          58.74       245.2   \n567                   20.60        29.33         140.10      1265.0   \n\nData Column     mean smoothness mean compactness mean concavity  \\\nPhysical Type           float64          float64        float64   \nLogical Type             Double           Double         Double   \nSemantic Tag(s)     ['numeric']      ['numeric']    ['numeric']   \n381                     0.07987          0.07079        0.03546   \n144                     0.07793          0.05139        0.02251   \n136                     0.10510          0.06095        0.03592   \n116                     0.09462          0.12430        0.09263   \n567                     0.11780          0.27700        0.35140   \n\nData Column     mean concave points mean symmetry mean fractal dimension  ...  \\\nPhysical Type               float64       float64                float64  ...   \nLogical Type                 Double        Double                 Double  ...   \nSemantic Tag(s)         ['numeric']   ['numeric']            ['numeric']  ...   \n381                        0.020740        0.2003                0.06246  ...   \n144                        0.007875        0.1399                0.05688  ...   \n136                        0.026000        0.1339                0.05945  ...   \n116                        0.023080        0.1305                0.07163  ...   \n567                        0.152000        0.2397                0.07016  ...   \n\nData Column     worst radius worst texture worst perimeter  worst area  \\\nPhysical Type        float64       float64         float64     float64   \nLogical Type          Double        Double          Double      Double   \nSemantic Tag(s)  ['numeric']   ['numeric']     ['numeric'] ['numeric']   \n381                   12.090         20.83           79.73       447.1   \n144                   11.950         20.72           77.79       441.2   \n136                   13.330         25.48           86.16       546.7   \n116                    9.414         17.07           63.34       270.0   \n567                   25.740         39.42          184.60      1821.0   \n\nData Column     worst smoothness worst compactness worst concavity  \\\nPhysical Type            float64           float64         float64   \nLogical Type              Double            Double          Double   \nSemantic Tag(s)      ['numeric']       ['numeric']     ['numeric']   \n381                       0.1095            0.1982         0.15530   \n144                       0.1076            0.1223         0.09755   \n136                       0.1271            0.1028         0.10460   \n116                       0.1179            0.1879         0.15440   \n567                       0.1650            0.8681         0.93870   \n\nData Column     worst concave points worst symmetry worst fractal dimension  \nPhysical Type                float64        float64                 float64  \nLogical Type                  Double         Double                  Double  \nSemantic Tag(s)          ['numeric']    ['numeric']             ['numeric']  \n381                          0.06754         0.3202                 0.07287  \n144                          0.03413         0.2300                 0.06769  \n136                          0.06968         0.1712                 0.07343  \n116                          0.03846         0.1652                 0.07722  \n567                          0.26500         0.4087                 0.12400  \n\n[5 rows x 30 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th>Data Column</th>\n      <th>mean radius</th>\n      <th>mean texture</th>\n      <th>mean perimeter</th>\n      <th>mean area</th>\n      <th>mean smoothness</th>\n      <th>mean compactness</th>\n      <th>mean concavity</th>\n      <th>mean concave points</th>\n      <th>mean symmetry</th>\n      <th>mean fractal dimension</th>\n      <th>...</th>\n      <th>worst radius</th>\n      <th>worst texture</th>\n      <th>worst perimeter</th>\n      <th>worst area</th>\n      <th>worst smoothness</th>\n      <th>worst compactness</th>\n      <th>worst concavity</th>\n      <th>worst concave points</th>\n      <th>worst symmetry</th>\n      <th>worst fractal dimension</th>\n    </tr>\n    <tr>\n      <th>Physical Type</th>\n      <th>float64</th>\n      <th>float64</th>\n      <th>float64</th>\n      <th>float64</th>\n      <th>float64</th>\n      <th>float64</th>\n      <th>float64</th>\n      <th>float64</th>\n      <th>float64</th>\n      <th>float64</th>\n      <th>...</th>\n      <th>float64</th>\n      <th>float64</th>\n      <th>float64</th>\n      <th>float64</th>\n      <th>float64</th>\n      <th>float64</th>\n      <th>float64</th>\n      <th>float64</th>\n      <th>float64</th>\n      <th>float64</th>\n    </tr>\n    <tr>\n      <th>Logical Type</th>\n      <th>Double</th>\n      <th>Double</th>\n      <th>Double</th>\n      <th>Double</th>\n      <th>Double</th>\n      <th>Double</th>\n      <th>Double</th>\n      <th>Double</th>\n      <th>Double</th>\n      <th>Double</th>\n      <th>...</th>\n      <th>Double</th>\n      <th>Double</th>\n      <th>Double</th>\n      <th>Double</th>\n      <th>Double</th>\n      <th>Double</th>\n      <th>Double</th>\n      <th>Double</th>\n      <th>Double</th>\n      <th>Double</th>\n    </tr>\n    <tr>\n      <th>Semantic Tag(s)</th>\n      <th>['numeric']</th>\n      <th>['numeric']</th>\n      <th>['numeric']</th>\n      <th>['numeric']</th>\n      <th>['numeric']</th>\n      <th>['numeric']</th>\n      <th>['numeric']</th>\n      <th>['numeric']</th>\n      <th>['numeric']</th>\n      <th>['numeric']</th>\n      <th>...</th>\n      <th>['numeric']</th>\n      <th>['numeric']</th>\n      <th>['numeric']</th>\n      <th>['numeric']</th>\n      <th>['numeric']</th>\n      <th>['numeric']</th>\n      <th>['numeric']</th>\n      <th>['numeric']</th>\n      <th>['numeric']</th>\n      <th>['numeric']</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>381</th>\n      <td>11.04</td>\n      <td>14.93</td>\n      <td>70.67</td>\n      <td>372.7</td>\n      <td>0.07987</td>\n      <td>0.07079</td>\n      <td>0.03546</td>\n      <td>0.020740</td>\n      <td>0.2003</td>\n      <td>0.06246</td>\n      <td>...</td>\n      <td>12.090</td>\n      <td>20.83</td>\n      <td>79.73</td>\n      <td>447.1</td>\n      <td>0.1095</td>\n      <td>0.1982</td>\n      <td>0.15530</td>\n      <td>0.06754</td>\n      <td>0.3202</td>\n      <td>0.07287</td>\n    </tr>\n    <tr>\n      <th>144</th>\n      <td>10.75</td>\n      <td>14.97</td>\n      <td>68.26</td>\n      <td>355.3</td>\n      <td>0.07793</td>\n      <td>0.05139</td>\n      <td>0.02251</td>\n      <td>0.007875</td>\n      <td>0.1399</td>\n      <td>0.05688</td>\n      <td>...</td>\n      <td>11.950</td>\n      <td>20.72</td>\n      <td>77.79</td>\n      <td>441.2</td>\n      <td>0.1076</td>\n      <td>0.1223</td>\n      <td>0.09755</td>\n      <td>0.03413</td>\n      <td>0.2300</td>\n      <td>0.06769</td>\n    </tr>\n    <tr>\n      <th>136</th>\n      <td>11.71</td>\n      <td>16.67</td>\n      <td>74.72</td>\n      <td>423.6</td>\n      <td>0.10510</td>\n      <td>0.06095</td>\n      <td>0.03592</td>\n      <td>0.026000</td>\n      <td>0.1339</td>\n      <td>0.05945</td>\n      <td>...</td>\n      <td>13.330</td>\n      <td>25.48</td>\n      <td>86.16</td>\n      <td>546.7</td>\n      <td>0.1271</td>\n      <td>0.1028</td>\n      <td>0.10460</td>\n      <td>0.06968</td>\n      <td>0.1712</td>\n      <td>0.07343</td>\n    </tr>\n    <tr>\n      <th>116</th>\n      <td>8.95</td>\n      <td>15.76</td>\n      <td>58.74</td>\n      <td>245.2</td>\n      <td>0.09462</td>\n      <td>0.12430</td>\n      <td>0.09263</td>\n      <td>0.023080</td>\n      <td>0.1305</td>\n      <td>0.07163</td>\n      <td>...</td>\n      <td>9.414</td>\n      <td>17.07</td>\n      <td>63.34</td>\n      <td>270.0</td>\n      <td>0.1179</td>\n      <td>0.1879</td>\n      <td>0.15440</td>\n      <td>0.03846</td>\n      <td>0.1652</td>\n      <td>0.07722</td>\n    </tr>\n    <tr>\n      <th>567</th>\n      <td>20.60</td>\n      <td>29.33</td>\n      <td>140.10</td>\n      <td>1265.0</td>\n      <td>0.11780</td>\n      <td>0.27700</td>\n      <td>0.35140</td>\n      <td>0.152000</td>\n      <td>0.2397</td>\n      <td>0.07016</td>\n      <td>...</td>\n      <td>25.740</td>\n      <td>39.42</td>\n      <td>184.60</td>\n      <td>1821.0</td>\n      <td>0.1650</td>\n      <td>0.8681</td>\n      <td>0.93870</td>\n      <td>0.26500</td>\n      <td>0.4087</td>\n      <td>0.12400</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 30 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Automated pipeline search","metadata":{}},{"cell_type":"markdown","source":"User can use AutoMLSearch() for searching the best pipeline. EvalML uses Bayesian optimization to sort the best pipeline as per the defined objective","metadata":{}},{"cell_type":"code","source":"from evalml.automl import AutoMLSearch\nautoml = AutoMLSearch(X_train=X_train, y_train=y_train, problem_type='binary')","metadata":{"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Using default limit of max_batches=1.\n\nGenerating pipelines to search over...\n","output_type":"stream"}]},{"cell_type":"markdown","source":"when you use search() function after automl.search() then the search for best pipeline is started. The need for data wrangling is eliminated in EvalML, you can directly load the data and start seaching for the best pipeline after defining feature and outcome variable, let's find the best pipeline now ","metadata":{}},{"cell_type":"code","source":"automl.search()","metadata":{"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"\n*****************************\n* Beginning pipeline search *\n*****************************\n\nOptimizing for Log Loss Binary. \nLower score is better.\n\nUsing SequentialEngine to train and score pipelines.\nSearching up to 1 batches for a total of 9 pipelines. \nAllowed model families: catboost, linear_model, decision_tree, random_forest, extra_trees, xgboost, lightgbm\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"FigureWidget({\n    'data': [{'mode': 'lines+markers',\n              'name': 'Best Score',\n              'type'…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a411713281484b1faff293a576c3b306"}},"metadata":{}},{"name":"stdout","text":"Evaluating Baseline Pipeline: Mode Baseline Binary Classification Pipeline\nMode Baseline Binary Classification Pipeline:\n\tStarting cross validation\n\tFinished cross validation - mean Log Loss Binary: 12.904\n\n*****************************\n* Evaluating Batch Number 1 *\n*****************************\n\nElastic Net Classifier w/ Imputer + Standard Scaler:\n\tStarting cross validation\n\tFinished cross validation - mean Log Loss Binary: 0.506\nDecision Tree Classifier w/ Imputer:\n\tStarting cross validation\n\tFinished cross validation - mean Log Loss Binary: 2.432\n\tHigh coefficient of variation (cv >= 0.2) within cross validation scores.\n\tDecision Tree Classifier w/ Imputer may not perform as estimated on unseen data.\nRandom Forest Classifier w/ Imputer:\n\tStarting cross validation\n\tFinished cross validation - mean Log Loss Binary: 0.120\nLightGBM Classifier w/ Imputer:\n\tStarting cross validation\n\tFinished cross validation - mean Log Loss Binary: 0.133\nLogistic Regression Classifier w/ Imputer + Standard Scaler:\n\tStarting cross validation\n\tFinished cross validation - mean Log Loss Binary: 0.094\n\tHigh coefficient of variation (cv >= 0.2) within cross validation scores.\n\tLogistic Regression Classifier w/ Imputer + Standard Scaler may not perform as estimated on unseen data.\nXGBoost Classifier w/ Imputer:\n\tStarting cross validation\n\tFinished cross validation - mean Log Loss Binary: 0.113\n\tHigh coefficient of variation (cv >= 0.2) within cross validation scores.\n\tXGBoost Classifier w/ Imputer may not perform as estimated on unseen data.\nExtra Trees Classifier w/ Imputer:\n\tStarting cross validation\n\tFinished cross validation - mean Log Loss Binary: 0.137\nCatBoost Classifier w/ Imputer:\n\tStarting cross validation\n\tFinished cross validation - mean Log Loss Binary: 0.386\n\nSearch finished after 00:14            \nBest pipeline: Logistic Regression Classifier w/ Imputer + Standard Scaler\nBest pipeline Log Loss Binary: 0.094015\n","output_type":"stream"}]},{"cell_type":"markdown","source":"So from the above snippet we got the best pipline i.e \"*Logistic Regression Classifier w/ Imputer + Standard Scaler*\" with Log loss of 0.094\n\nAfter the search we will rank the pipeline on the basis of scores, for this we need to use a simple code \n<automl.rankings>","metadata":{}},{"cell_type":"code","source":"automl.rankings","metadata":{"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"   id                                      pipeline_name  mean_cv_score  \\\n0   5  Logistic Regression Classifier w/ Imputer + St...       0.094015   \n1   6                      XGBoost Classifier w/ Imputer       0.113098   \n2   3                Random Forest Classifier w/ Imputer       0.119972   \n3   4                     LightGBM Classifier w/ Imputer       0.132722   \n4   7                  Extra Trees Classifier w/ Imputer       0.136959   \n5   8                     CatBoost Classifier w/ Imputer       0.386387   \n6   1  Elastic Net Classifier w/ Imputer + Standard S...       0.505862   \n7   2                Decision Tree Classifier w/ Imputer       2.431916   \n8   0       Mode Baseline Binary Classification Pipeline      12.904388   \n\n   standard_deviation_cv_score  validation_score  \\\n0                     0.033791          0.060529   \n1                     0.038613          0.069048   \n2                     0.019487          0.099614   \n3                     0.024842          0.110679   \n4                     0.022862          0.111169   \n5                     0.011583          0.374338   \n6                     0.008317          0.496767   \n7                     0.531935          2.726782   \n8                     0.082537         12.952041   \n\n   percent_better_than_baseline  high_variance_cv  \\\n0                     99.271446              True   \n1                     99.123568              True   \n2                     99.070299             False   \n3                     98.971496             False   \n4                     98.938661             False   \n5                     97.005774             False   \n6                     96.079926             False   \n7                     81.154350              True   \n8                      0.000000             False   \n\n                                          parameters  \n0  {'Imputer': {'categorical_impute_strategy': 'm...  \n1  {'Imputer': {'categorical_impute_strategy': 'm...  \n2  {'Imputer': {'categorical_impute_strategy': 'm...  \n3  {'Imputer': {'categorical_impute_strategy': 'm...  \n4  {'Imputer': {'categorical_impute_strategy': 'm...  \n5  {'Imputer': {'categorical_impute_strategy': 'm...  \n6  {'Imputer': {'categorical_impute_strategy': 'm...  \n7  {'Imputer': {'categorical_impute_strategy': 'm...  \n8      {'Baseline Classifier': {'strategy': 'mode'}}  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>pipeline_name</th>\n      <th>mean_cv_score</th>\n      <th>standard_deviation_cv_score</th>\n      <th>validation_score</th>\n      <th>percent_better_than_baseline</th>\n      <th>high_variance_cv</th>\n      <th>parameters</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5</td>\n      <td>Logistic Regression Classifier w/ Imputer + St...</td>\n      <td>0.094015</td>\n      <td>0.033791</td>\n      <td>0.060529</td>\n      <td>99.271446</td>\n      <td>True</td>\n      <td>{'Imputer': {'categorical_impute_strategy': 'm...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6</td>\n      <td>XGBoost Classifier w/ Imputer</td>\n      <td>0.113098</td>\n      <td>0.038613</td>\n      <td>0.069048</td>\n      <td>99.123568</td>\n      <td>True</td>\n      <td>{'Imputer': {'categorical_impute_strategy': 'm...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Random Forest Classifier w/ Imputer</td>\n      <td>0.119972</td>\n      <td>0.019487</td>\n      <td>0.099614</td>\n      <td>99.070299</td>\n      <td>False</td>\n      <td>{'Imputer': {'categorical_impute_strategy': 'm...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>LightGBM Classifier w/ Imputer</td>\n      <td>0.132722</td>\n      <td>0.024842</td>\n      <td>0.110679</td>\n      <td>98.971496</td>\n      <td>False</td>\n      <td>{'Imputer': {'categorical_impute_strategy': 'm...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>Extra Trees Classifier w/ Imputer</td>\n      <td>0.136959</td>\n      <td>0.022862</td>\n      <td>0.111169</td>\n      <td>98.938661</td>\n      <td>False</td>\n      <td>{'Imputer': {'categorical_impute_strategy': 'm...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>8</td>\n      <td>CatBoost Classifier w/ Imputer</td>\n      <td>0.386387</td>\n      <td>0.011583</td>\n      <td>0.374338</td>\n      <td>97.005774</td>\n      <td>False</td>\n      <td>{'Imputer': {'categorical_impute_strategy': 'm...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1</td>\n      <td>Elastic Net Classifier w/ Imputer + Standard S...</td>\n      <td>0.505862</td>\n      <td>0.008317</td>\n      <td>0.496767</td>\n      <td>96.079926</td>\n      <td>False</td>\n      <td>{'Imputer': {'categorical_impute_strategy': 'm...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2</td>\n      <td>Decision Tree Classifier w/ Imputer</td>\n      <td>2.431916</td>\n      <td>0.531935</td>\n      <td>2.726782</td>\n      <td>81.154350</td>\n      <td>True</td>\n      <td>{'Imputer': {'categorical_impute_strategy': 'm...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0</td>\n      <td>Mode Baseline Binary Classification Pipeline</td>\n      <td>12.904388</td>\n      <td>0.082537</td>\n      <td>12.952041</td>\n      <td>0.000000</td>\n      <td>False</td>\n      <td>{'Baseline Classifier': {'strategy': 'mode'}}</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"As per the table Logistic Regression is the best pipeline with high mean_cv_score and validation_score, we can can get the description of the pipeline now by using <automl.describe_pipeline(5)> where \"5\" is the pipeline ID \n\n","metadata":{}},{"cell_type":"code","source":"automl.describe_pipeline(5)","metadata":{"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"\n***************************************************************\n* Logistic Regression Classifier w/ Imputer + Standard Scaler *\n***************************************************************\n\nProblem Type: binary\nModel Family: Linear\n\nPipeline Steps\n==============\n1. Imputer\n\t * categorical_impute_strategy : most_frequent\n\t * numeric_impute_strategy : mean\n\t * categorical_fill_value : None\n\t * numeric_fill_value : None\n2. Standard Scaler\n3. Logistic Regression Classifier\n\t * penalty : l2\n\t * C : 1.0\n\t * n_jobs : -1\n\t * multi_class : auto\n\t * solver : lbfgs\n\nTraining\n========\nTraining for binary problems.\nTotal training time (including CV): 3.7 seconds\n\nCross Validation\n----------------\n             Log Loss Binary  MCC Binary   AUC  Precision    F1  Balanced Accuracy Binary  Accuracy Binary  Sensitivity at Low Alert Rates # Training # Validation\n0                      0.061       0.958 0.997      0.966 0.974                     0.981            0.980                           0.412        303          152\n1                      0.128       0.930 0.984      0.981 0.955                     0.960            0.967                           0.333        303          152\n2                      0.093       0.944 0.993      1.000 0.963                     0.964            0.974                           0.261        304          151\nmean                   0.094       0.944 0.991      0.982 0.964                     0.968            0.974                           0.335          -            -\nstd                    0.034       0.014 0.006      0.017 0.010                     0.011            0.007                           0.075          -            -\ncoef of var            0.359       0.015 0.007      0.018 0.010                     0.011            0.007                           0.225          -            -\n","output_type":"stream"}]},{"cell_type":"markdown","source":"We can easily check all the parameteres of any pipeline using pipeline ID","metadata":{}},{"cell_type":"code","source":"pipeline = automl.get_pipeline(1)\nprint(pipeline.name)\nprint(pipeline.parameters)","metadata":{"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Elastic Net Classifier w/ Imputer + Standard Scaler\n{'Imputer': {'categorical_impute_strategy': 'most_frequent', 'numeric_impute_strategy': 'mean', 'categorical_fill_value': None, 'numeric_fill_value': None}, 'Elastic Net Classifier': {'alpha': 0.5, 'l1_ratio': 0.5, 'n_jobs': -1, 'max_iter': 1000, 'penalty': 'elasticnet', 'loss': 'log'}}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Check the best pipeline required to build a model","metadata":{}},{"cell_type":"code","source":"best_pipeline = automl.best_pipeline","metadata":{"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"# Evaluate the pipeline performance by using it against the holdoff data","metadata":{}},{"cell_type":"code","source":"best_pipeline.score(X_test, y_test, objectives=[\"auc\",\"f1\",\"Precision\",\"Recall\"])","metadata":{"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"OrderedDict([('AUC', 0.9933862433862434),\n             ('F1', 0.963855421686747),\n             ('Precision', 0.975609756097561),\n             ('Recall', 0.9523809523809523)])"},"metadata":{}}]},{"cell_type":"markdown","source":"## From here you can change the objective of the model you've built using EvalML","metadata":{}},{"cell_type":"code","source":"automl_auc = AutoMLSearch(X_train=X_train, y_train=y_train,\n                          problem_type='binary',\n                          objective='auc',\n                          additional_objectives=['f1', 'precision'],\n                          max_batches=1,\n                          optimize_thresholds=True)\n\nautoml_auc.search()","metadata":{"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Generating pipelines to search over...\n\n*****************************\n* Beginning pipeline search *\n*****************************\n\nOptimizing for AUC. \nGreater score is better.\n\nUsing SequentialEngine to train and score pipelines.\nSearching up to 1 batches for a total of 9 pipelines. \nAllowed model families: catboost, linear_model, decision_tree, random_forest, extra_trees, xgboost, lightgbm\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"FigureWidget({\n    'data': [{'mode': 'lines+markers',\n              'name': 'Best Score',\n              'type'…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb320c6e068e419fb37827a7cb32f880"}},"metadata":{}},{"name":"stdout","text":"Evaluating Baseline Pipeline: Mode Baseline Binary Classification Pipeline\nMode Baseline Binary Classification Pipeline:\n\tStarting cross validation\n\tFinished cross validation - mean AUC: 0.500\n\n*****************************\n* Evaluating Batch Number 1 *\n*****************************\n\nElastic Net Classifier w/ Imputer + Standard Scaler:\n\tStarting cross validation\n\tFinished cross validation - mean AUC: 0.985\nDecision Tree Classifier w/ Imputer:\n\tStarting cross validation\n\tFinished cross validation - mean AUC: 0.923\nRandom Forest Classifier w/ Imputer:\n\tStarting cross validation\n\tFinished cross validation - mean AUC: 0.992\nLightGBM Classifier w/ Imputer:\n\tStarting cross validation\n\tFinished cross validation - mean AUC: 0.991\nLogistic Regression Classifier w/ Imputer + Standard Scaler:\n\tStarting cross validation\n\tFinished cross validation - mean AUC: 0.991\nXGBoost Classifier w/ Imputer:\n\tStarting cross validation\n\tFinished cross validation - mean AUC: 0.991\nExtra Trees Classifier w/ Imputer:\n\tStarting cross validation\n\tFinished cross validation - mean AUC: 0.993\nCatBoost Classifier w/ Imputer:\n\tStarting cross validation\n\tFinished cross validation - mean AUC: 0.991\n\nSearch finished after 00:12            \nBest pipeline: Extra Trees Classifier w/ Imputer\nBest pipeline AUC: 0.992791\n","output_type":"stream"}]},{"cell_type":"markdown","source":"The objective to optimize for. Used to propose and rank pipelines, but not for optimizing each pipeline during fit-time.\n When set to 'auto', chooses:\n*     - LogLossBinary for binary classification problems,\n*     - LogLossMulticlass for multiclass classification problems, and\n*     - R^2 for regression problems.","metadata":{}},{"cell_type":"markdown","source":"# Save the model by pickling it","metadata":{}},{"cell_type":"code","source":"best_pipeline.save(\"model.pkl\")","metadata":{"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"# Evaluate the model by testing it against test data","metadata":{}},{"cell_type":"code","source":"check_model=automl.load('model.pkl')","metadata":{"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"check_model.predict_proba(X_test).to_dataframe()","metadata":{"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"           benign  malignant\n0    9.996252e-01   0.000375\n1    9.845724e-01   0.015428\n2    7.749595e-01   0.225040\n3    9.907312e-01   0.009269\n4    9.998272e-01   0.000173\n..            ...        ...\n109  9.990961e-01   0.000904\n110  7.981366e-01   0.201863\n111  9.999924e-01   0.000008\n112  1.082727e-08   1.000000\n113  9.999267e-01   0.000073\n\n[114 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>benign</th>\n      <th>malignant</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9.996252e-01</td>\n      <td>0.000375</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9.845724e-01</td>\n      <td>0.015428</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7.749595e-01</td>\n      <td>0.225040</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9.907312e-01</td>\n      <td>0.009269</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9.998272e-01</td>\n      <td>0.000173</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>109</th>\n      <td>9.990961e-01</td>\n      <td>0.000904</td>\n    </tr>\n    <tr>\n      <th>110</th>\n      <td>7.981366e-01</td>\n      <td>0.201863</td>\n    </tr>\n    <tr>\n      <th>111</th>\n      <td>9.999924e-01</td>\n      <td>0.000008</td>\n    </tr>\n    <tr>\n      <th>112</th>\n      <td>1.082727e-08</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>113</th>\n      <td>9.999267e-01</td>\n      <td>0.000073</td>\n    </tr>\n  </tbody>\n</table>\n<p>114 rows × 2 columns</p>\n</div>"},"metadata":{}}]}]}